# -*- coding: utf-8 -*-
"""Capstone_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NPVI833FhQxlmIMhbMM43qIdEKBT0euL

# **History Chatbot**
"""

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.stem.porter import PorterStemmer

nltk.download('stopwords')
nltk.download('wordnet')

stemmer = PorterStemmer()
lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

file_path = "History_Dataset.csv"
data = pd.read_csv(file_path)

assert "Question" in data.columns and "Answer" in data.columns, "CSV must have 'Question' and 'Answer' columns."

def preprocess(text):
    tokens = [word for word in text.split() if word.lower() not in stop_words]
    stemmed = [stemmer.stem(word) for word in tokens]
    lemmatized = [lemmatizer.lemmatize(word) for word in stemmed]
    return ' '.join(lemmatized)

data['ProcessedQuestion'] = data['Question'].apply(preprocess)
questions = data['ProcessedQuestion'].tolist()
answers = data['Answer'].tolist()

vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(questions)

def chatbot():
    print("Welcome to the History Chatbot!")
    print("You can ask questions using keywords like '1784', 'Powada', or names like 'Sir William Jones'.")
    print("Type 'exit' to end the session.")

    while True:
        user_query = input("\nType your question: ").strip()
        if user_query.lower() == "exit":
            print("Thank you for using the History Chatbot. Goodbye!")
            break

        query = preprocess(user_query)
        query_vector = vectorizer.transform([query])
        similarities = cosine_similarity(query_vector, tfidf_matrix)

        max_similarity_index = np.argmax(similarities)
        max_similarity_score = similarities[0][max_similarity_index]

        threshold = 0.7

        if max_similarity_score > threshold:
            response = answers[max_similarity_index]
            print(f"Answer: {response}")
        else:
            print("I'm not sure about that. Try using keywords or rephrasing your question.")

if __name__ == "__main__":
    chatbot()

import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Step 1: Load the test dataset
test_file_path = "/content/history_dataset.csv"  # Update with your test file path
test_data = pd.read_csv(test_file_path)

# Ensure data is in expected format
assert "Question" in test_data.columns and "Answer" in test_data.columns, "CSV must have 'Question' and 'Answer' columns."

# Step 2: Extract test questions and answers
test_questions = test_data['Question'].tolist()
test_answers = test_data['Answer'].tolist()

# Step 3: Evaluate the chatbot model
correct_predictions = 0
threshold = 0.3  # Similarity score threshold to consider a match

for i, test_question in enumerate(test_questions):
    # Transform the test question into the TF-IDF vector space
    test_vector = vectorizer.transform([test_question])
    similarities = cosine_similarity(test_vector, tfidf_matrix)

    # Get the most similar question from the training data
    max_similarity_index = np.argmax(similarities)
    max_similarity_score = similarities[0][max_similarity_index]

    # If the similarity score exceeds the threshold, retrieve the answer
    if max_similarity_score > threshold:
        predicted_answer = answers[max_similarity_index]
    else:
        predicted_answer = None  # Indicate no confident match found

    # Compare the predicted answer with the actual test answer
    if predicted_answer == test_answers[i]:
        correct_predictions += 1

# Step 4: Calculate accuracy
total_questions = len(test_questions)
accuracy = (correct_predictions / total_questions) * 100

print(f"Accuracy of the chatbot model: {accuracy:.2f}%")

